{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regressions\n",
    "---\n",
    "Now that we have clusters of the questions into different types of groups, we will be using them to generate linear models to see how they predict the usage of language.\n",
    "\n",
    "Each model will include:\n",
    "- How many years have you been learning/utilizing your learned language?\n",
    "- Do you speak this learned language at home?\n",
    "- Is this learned language spoken in your home?\n",
    "\n",
    "To prevent correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Stats Packages\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "\n",
    "# Import Data\n",
    "df = pd.read_csv('cleaned_data.csv')\n",
    "all_motives = json.load(open('motivator_clusters.json'))\n",
    "\n",
    "family_motives        = all_motives['family']\n",
    "education_motives     = all_motives['education']\n",
    "media_motives         = all_motives['media']\n",
    "self_improve_motives  = all_motives['self_improve']\n",
    "culture_motives       = all_motives['culture']\n",
    "citizenship_motives   = all_motives['citizenship']\n",
    "uncategorized_motives = all_motives['uncategorized']\n",
    "\n",
    "rank_only             = ['rank_family', 'rank_education', 'rank_media', \n",
    "                         'rank_improvement', 'rank_culture', 'rank_citizenship']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collection of all the motivator questions\n",
    "full_cols = family_motives + education_motives + media_motives + self_improve_motives + culture_motives + citizenship_motives + uncategorized_motives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current values for rank is 1 to 6 with 1 being the most important\n",
    "# Flip the values so that 1 is the least important and 6 is the most important\n",
    "df[rank_only] = df[rank_only].apply(lambda x: 7 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns of the dataframe which have 'feel_' in it \n",
    "feel_cols = [col for col in df.columns if 'feel_' in col]\n",
    "# Remove 'feel_current_grade' and 'feel_expected_grade' from the list\n",
    "feel_cols.remove('feel_current_grade')\n",
    "feel_cols.remove('feel_expected_grade')\n",
    "\n",
    "# Get the columns of our possible controlling\n",
    "controlling_list = ['demo_num_lang', 'demo_years_learning', 'demo_home_speaker', 'demo_home_spoken']\n",
    "controlling = ' + '.join(controlling_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeModel(dependent: list[str], motives: list[str], dataframe=df) -> list:\n",
    "    '''\n",
    "    Generates a list of the ols models computed for the dependent variable and formula\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dependent : str\n",
    "        The dependent variable\n",
    "    \n",
    "    formula : str\n",
    "        The formula to use for the ols model\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of the ols models computed for the dependent variable and formula\n",
    "    '''\n",
    "    global controlling\n",
    "    models = []\n",
    "    formula = '~ 1 +' + ' + '.join(motives) + ' + ' + controlling\n",
    "    for col in dependent:\n",
    "        model = ols((col + formula), data=dataframe).fit()\n",
    "        # Check to see if any of the p-values for the motives are less than 0.05\n",
    "        if any(model.pvalues[1:-4] < 0.05):\n",
    "            models.append(model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_models        = computeModel(feel_cols, family_motives)\n",
    "education_models     = computeModel(feel_cols, education_motives)\n",
    "media_models         = computeModel(feel_cols, media_motives)\n",
    "self_improve_models  = computeModel(feel_cols, self_improve_motives)\n",
    "culture_models       = computeModel(feel_cols, culture_motives)\n",
    "citizenship_models   = computeModel(feel_cols, citizenship_motives)\n",
    "uncategorized_models = computeModel(feel_cols, uncategorized_motives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a composite score which is the average of the sum of scores from each motives\n",
    "df['family_score']        = df[family_motives].sum(axis=1)/len(family_motives)\n",
    "df['education_score']     = df[education_motives].sum(axis=1)/len(education_motives)\n",
    "df['media_score']         = df[media_motives].sum(axis=1)/len(media_motives)\n",
    "df['self_improve_score']  = df[self_improve_motives].sum(axis=1)/len(self_improve_motives)\n",
    "df['culture_score']       = df[culture_motives].sum(axis=1)/len(culture_motives)\n",
    "df['citizenship_score']   = df[citizenship_motives].sum(axis=1)/len(citizenship_motives)\n",
    "df['uncategorized_score'] = df[uncategorized_motives].sum(axis=1)/len(uncategorized_motives)\n",
    "\n",
    "\n",
    "# Make one large model for all the motives\n",
    "composite_scores = ['family_score', 'education_score', 'media_score', 'self_improve_score', 'culture_score', 'citizenship_score', 'uncategorized_score']\n",
    "\n",
    "all_models = computeModel(feel_cols, composite_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a \"full\" model which uses every motive and rank as a predictor\n",
    "full_model = computeModel(feel_cols, family_motives + education_motives + media_motives + self_improve_motives + culture_motives + citizenship_motives + uncategorized_motives + rank_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>feel_comfortable_listening</td> <th>  R-squared:         </th> <td>   0.629</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                        <td>OLS</td>            <th>  Adj. R-squared:    </th> <td>   0.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>Least Squares</td>       <th>  F-statistic:       </th> <td>   2.525</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                  <td>Mon, 12 Jun 2023</td>      <th>  Prob (F-statistic):</th> <td>0.000899</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                      <td>14:27:31</td>          <th>  Log-Likelihood:    </th> <td> -166.13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>           <td>    93</td>           <th>  AIC:               </th> <td>   408.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>               <td>    55</td>           <th>  BIC:               </th> <td>   504.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>                   <td>    37</td>           <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>           <td>nonrobust</td>         <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                     <td>    0.0478</td> <td>    0.032</td> <td>    1.490</td> <td> 0.142</td> <td>   -0.016</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_continue</th>     <td>    0.2093</td> <td>    0.142</td> <td>    1.477</td> <td> 0.145</td> <td>   -0.075</td> <td>    0.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_encourage</th>    <td>   -0.2071</td> <td>    0.171</td> <td>   -1.208</td> <td> 0.232</td> <td>   -0.551</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_stressed</th>     <td>    0.0875</td> <td>    0.112</td> <td>    0.779</td> <td> 0.439</td> <td>   -0.138</td> <td>    0.312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_important</th>    <td>   -0.0756</td> <td>    0.211</td> <td>   -0.358</td> <td> 0.722</td> <td>   -0.499</td> <td>    0.348</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_required</th>            <td>    0.0360</td> <td>    0.081</td> <td>    0.444</td> <td> 0.659</td> <td>   -0.127</td> <td>    0.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_choose_not</th>          <td>   -0.1441</td> <td>    0.138</td> <td>   -1.047</td> <td> 0.300</td> <td>   -0.420</td> <td>    0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_nervous</th>             <td>   -0.2875</td> <td>    0.105</td> <td>   -2.751</td> <td> 0.008</td> <td>   -0.497</td> <td>   -0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_difficult</th>           <td>   -0.0509</td> <td>    0.117</td> <td>   -0.435</td> <td> 0.665</td> <td>   -0.285</td> <td>    0.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_newspapers</th>          <td>   -0.2950</td> <td>    0.129</td> <td>   -2.287</td> <td> 0.026</td> <td>   -0.554</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_tv</th>                  <td>    0.2249</td> <td>    0.124</td> <td>    1.818</td> <td> 0.075</td> <td>   -0.023</td> <td>    0.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_understand</th>          <td>    0.2146</td> <td>    0.113</td> <td>    1.903</td> <td> 0.062</td> <td>   -0.011</td> <td>    0.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_speak</th>               <td>    0.1879</td> <td>    0.180</td> <td>    1.044</td> <td> 0.301</td> <td>   -0.173</td> <td>    0.549</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_many</th>                <td>    0.0132</td> <td>    0.148</td> <td>    0.089</td> <td> 0.929</td> <td>   -0.284</td> <td>    0.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_practical</th>           <td>    0.2949</td> <td>    0.130</td> <td>    2.269</td> <td> 0.027</td> <td>    0.034</td> <td>    0.555</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_career</th>              <td>    0.0907</td> <td>    0.125</td> <td>    0.727</td> <td> 0.471</td> <td>   -0.160</td> <td>    0.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_job</th>                 <td>    0.0260</td> <td>    0.127</td> <td>    0.204</td> <td> 0.839</td> <td>   -0.229</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_educated</th>            <td>   -0.0115</td> <td>    0.222</td> <td>   -0.052</td> <td> 0.959</td> <td>   -0.457</td> <td>    0.434</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_converse</th>            <td>   -0.1176</td> <td>    0.234</td> <td>   -0.502</td> <td> 0.618</td> <td>   -0.587</td> <td>    0.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_understand_cultural</th> <td>   -0.0181</td> <td>    0.199</td> <td>   -0.091</td> <td> 0.928</td> <td>   -0.417</td> <td>    0.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_interact</th>            <td>   -0.0273</td> <td>    0.190</td> <td>   -0.144</td> <td> 0.886</td> <td>   -0.408</td> <td>    0.353</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_great</th>               <td>   -0.0047</td> <td>    0.236</td> <td>   -0.020</td> <td> 0.984</td> <td>   -0.477</td> <td>    0.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_communicate</th>         <td>    0.1117</td> <td>    0.178</td> <td>    0.627</td> <td> 0.533</td> <td>   -0.246</td> <td>    0.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_natural</th>             <td>   -0.3416</td> <td>    0.230</td> <td>   -1.488</td> <td> 0.142</td> <td>   -0.802</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_fluent</th>              <td>   -0.0281</td> <td>    0.236</td> <td>   -0.119</td> <td> 0.906</td> <td>   -0.500</td> <td>    0.444</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_aspects</th>             <td>    0.4971</td> <td>    0.200</td> <td>    2.481</td> <td> 0.016</td> <td>    0.096</td> <td>    0.899</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_choose</th>              <td>   -0.1099</td> <td>    0.125</td> <td>   -0.879</td> <td> 0.383</td> <td>   -0.360</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_friends</th>             <td>   -0.1153</td> <td>    0.153</td> <td>   -0.755</td> <td> 0.453</td> <td>   -0.421</td> <td>    0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_read</th>                <td>    0.0382</td> <td>    0.117</td> <td>    0.325</td> <td> 0.746</td> <td>   -0.197</td> <td>    0.273</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_family</th>                   <td>    0.1600</td> <td>    0.189</td> <td>    0.845</td> <td> 0.402</td> <td>   -0.219</td> <td>    0.539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_education</th>                <td>   -0.0254</td> <td>    0.231</td> <td>   -0.110</td> <td> 0.913</td> <td>   -0.488</td> <td>    0.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_media</th>                    <td>    0.4806</td> <td>    0.215</td> <td>    2.237</td> <td> 0.029</td> <td>    0.050</td> <td>    0.911</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_improvement</th>              <td>    0.2304</td> <td>    0.187</td> <td>    1.232</td> <td> 0.223</td> <td>   -0.144</td> <td>    0.605</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_culture</th>                  <td>    0.0576</td> <td>    0.239</td> <td>    0.241</td> <td> 0.810</td> <td>   -0.421</td> <td>    0.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_citizenship</th>              <td>    0.1005</td> <td>    0.212</td> <td>    0.473</td> <td> 0.638</td> <td>   -0.325</td> <td>    0.526</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_num_lang</th>                 <td>   -0.2349</td> <td>    0.379</td> <td>   -0.620</td> <td> 0.538</td> <td>   -0.994</td> <td>    0.524</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_years_learning</th>           <td>    0.4535</td> <td>    0.121</td> <td>    3.758</td> <td> 0.000</td> <td>    0.212</td> <td>    0.695</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_home_speaker</th>             <td>    0.1527</td> <td>    1.014</td> <td>    0.151</td> <td> 0.881</td> <td>   -1.879</td> <td>    2.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_home_spoken</th>              <td>    0.0397</td> <td>    1.034</td> <td>    0.038</td> <td> 0.970</td> <td>   -2.033</td> <td>    2.112</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.470</td> <th>  Durbin-Watson:     </th> <td>   1.938</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.479</td> <th>  Jarque-Bera (JB):  </th> <td>   1.296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.131</td> <th>  Prob(JB):          </th> <td>   0.523</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.484</td> <th>  Cond. No.          </th> <td>5.77e+17</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 4.33e-31. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                OLS Regression Results                                \n",
       "======================================================================================\n",
       "Dep. Variable:     feel_comfortable_listening   R-squared:                       0.629\n",
       "Model:                                    OLS   Adj. R-squared:                  0.380\n",
       "Method:                         Least Squares   F-statistic:                     2.525\n",
       "Date:                        Mon, 12 Jun 2023   Prob (F-statistic):           0.000899\n",
       "Time:                                14:27:31   Log-Likelihood:                -166.13\n",
       "No. Observations:                          93   AIC:                             408.3\n",
       "Df Residuals:                              55   BIC:                             504.5\n",
       "Df Model:                                  37                                         \n",
       "Covariance Type:                    nonrobust                                         \n",
       "=================================================================================================\n",
       "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "Intercept                         0.0478      0.032      1.490      0.142      -0.016       0.112\n",
       "motivator_family_continue         0.2093      0.142      1.477      0.145      -0.075       0.493\n",
       "motivator_family_encourage       -0.2071      0.171     -1.208      0.232      -0.551       0.136\n",
       "motivator_family_stressed         0.0875      0.112      0.779      0.439      -0.138       0.312\n",
       "motivator_family_important       -0.0756      0.211     -0.358      0.722      -0.499       0.348\n",
       "motivator_required                0.0360      0.081      0.444      0.659      -0.127       0.199\n",
       "motivator_choose_not             -0.1441      0.138     -1.047      0.300      -0.420       0.132\n",
       "motivator_nervous                -0.2875      0.105     -2.751      0.008      -0.497      -0.078\n",
       "motivator_difficult              -0.0509      0.117     -0.435      0.665      -0.285       0.183\n",
       "motivator_newspapers             -0.2950      0.129     -2.287      0.026      -0.554      -0.036\n",
       "motivator_tv                      0.2249      0.124      1.818      0.075      -0.023       0.473\n",
       "motivator_understand              0.2146      0.113      1.903      0.062      -0.011       0.441\n",
       "motivator_speak                   0.1879      0.180      1.044      0.301      -0.173       0.549\n",
       "motivator_many                    0.0132      0.148      0.089      0.929      -0.284       0.311\n",
       "motivator_practical               0.2949      0.130      2.269      0.027       0.034       0.555\n",
       "motivator_career                  0.0907      0.125      0.727      0.471      -0.160       0.341\n",
       "motivator_job                     0.0260      0.127      0.204      0.839      -0.229       0.281\n",
       "motivator_educated               -0.0115      0.222     -0.052      0.959      -0.457       0.434\n",
       "motivator_converse               -0.1176      0.234     -0.502      0.618      -0.587       0.352\n",
       "motivator_understand_cultural    -0.0181      0.199     -0.091      0.928      -0.417       0.381\n",
       "motivator_interact               -0.0273      0.190     -0.144      0.886      -0.408       0.353\n",
       "motivator_great                  -0.0047      0.236     -0.020      0.984      -0.477       0.468\n",
       "motivator_communicate             0.1117      0.178      0.627      0.533      -0.246       0.469\n",
       "motivator_natural                -0.3416      0.230     -1.488      0.142      -0.802       0.119\n",
       "motivator_fluent                 -0.0281      0.236     -0.119      0.906      -0.500       0.444\n",
       "motivator_aspects                 0.4971      0.200      2.481      0.016       0.096       0.899\n",
       "motivator_choose                 -0.1099      0.125     -0.879      0.383      -0.360       0.141\n",
       "motivator_friends                -0.1153      0.153     -0.755      0.453      -0.421       0.191\n",
       "motivator_read                    0.0382      0.117      0.325      0.746      -0.197       0.273\n",
       "rank_family                       0.1600      0.189      0.845      0.402      -0.219       0.539\n",
       "rank_education                   -0.0254      0.231     -0.110      0.913      -0.488       0.437\n",
       "rank_media                        0.4806      0.215      2.237      0.029       0.050       0.911\n",
       "rank_improvement                  0.2304      0.187      1.232      0.223      -0.144       0.605\n",
       "rank_culture                      0.0576      0.239      0.241      0.810      -0.421       0.536\n",
       "rank_citizenship                  0.1005      0.212      0.473      0.638      -0.325       0.526\n",
       "demo_num_lang                    -0.2349      0.379     -0.620      0.538      -0.994       0.524\n",
       "demo_years_learning               0.4535      0.121      3.758      0.000       0.212       0.695\n",
       "demo_home_speaker                 0.1527      1.014      0.151      0.881      -1.879       2.184\n",
       "demo_home_spoken                  0.0397      1.034      0.038      0.970      -2.033       2.112\n",
       "==============================================================================\n",
       "Omnibus:                        1.470   Durbin-Watson:                   1.938\n",
       "Prob(Omnibus):                  0.479   Jarque-Bera (JB):                1.296\n",
       "Skew:                          -0.131   Prob(JB):                        0.523\n",
       "Kurtosis:                       2.484   Cond. No.                     5.77e+17\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 4.33e-31. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(full_model[10].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_model = computeModel(feel_cols, rank_only)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "---\n",
    "Viewing all the OLS Models for each cluster of motivating questions as well as the ranks, we find that they are all hovering at a very low rate of explanatory variation, indicated by the $R^2$ value. The model which appears to perform the best is the Full Model, which makes intuitive sense as more predictors would typically entail more variation being accounted for. However, this in combination with the cluster analysis demonstrating that the Ranks $\\neq$ Motivatoring Questions, it may be more logical to progress forward using the entire model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engagement Predictor\n",
    "---\n",
    "The next following OLS will be to oversee how students engage with the language course material relative to their motivators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns of the dataframe which have 'engage_' in it \n",
    "engage_cols = [col for col in df.columns if 'engage_' in col]\n",
    "\n",
    "engage_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the values from the engage columns to respective categories\n",
    "engage_dict = {1: \"Very Often\", 2: \"Often\", 3: \"Sometimes\", 4: \"Occassionally\", 5: \"Infrequently\", 6: \"Rarely\", 7: \"Never\"}\n",
    "\n",
    "engage_df[engage_cols] = engage_df[engage_cols].replace(engage_dict)\n",
    "\n",
    "# Convert the engage columns to categorical data type\n",
    "engage_df[engage_cols] = engage_df[engage_cols]\\\n",
    "                        .astype(CategoricalDtype(categories=list(reversed(engage_dict.values())), \n",
    "                                                 ordered=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Very Often', 'Often', 'Never', 'Sometimes']\n",
       "Categories (7, object): ['Never' < 'Rarely' < 'Infrequently' < 'Occassionally' < 'Sometimes' < 'Often' < 'Very Often']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engage_df['engage_attend_class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['engage_attend_class',\n",
       " 'engage_participate_class',\n",
       " 'engage_apps',\n",
       " 'engage_practice_others',\n",
       " 'engage_listen',\n",
       " 'engage_read',\n",
       " 'engage_watch']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engage_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_formula = engage_cols[3] + ' ~ -1' + ' + ' + controlling + ' + ' + ' + '.join(full_cols) + ' + ' + ' + '.join(rank_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'engage_practice_others ~ -1 + demo_num_lang + demo_years_learning + demo_home_speaker + demo_home_spoken + motivator_family_continue + motivator_family_encourage + motivator_family_stressed + motivator_family_important + motivator_required + motivator_choose_not + motivator_nervous + motivator_difficult + motivator_newspapers + motivator_tv + motivator_understand + motivator_speak + motivator_many + motivator_practical + motivator_career + motivator_job + motivator_educated + motivator_converse + motivator_understand_cultural + motivator_interact + motivator_great + motivator_communicate + motivator_natural + motivator_fluent + motivator_aspects + motivator_choose + motivator_friends + motivator_read + rank_family + rank_education + rank_media + rank_improvement + rank_culture + rank_citizenship'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.257584\n",
      "         Iterations: 52\n",
      "         Function evaluations: 58\n",
      "         Gradient evaluations: 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OrderedModel Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>engage_practice_others</td> <th>  Log-Likelihood:    </th> <td> -116.96</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>OrderedModel</td>      <th>  AIC:               </th> <td>   321.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Maximum Likelihood</td>   <th>  BIC:               </th> <td>   433.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                <td>Mon, 12 Jun 2023</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                    <td>14:41:32</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>         <td>    93</td>         <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>             <td>    49</td>         <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>                 <td>    44</td>         <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_num_lang</th>                 <td>   -0.4986</td> <td>    0.220</td> <td>   -2.262</td> <td> 0.024</td> <td>   -0.931</td> <td>   -0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_years_learning</th>           <td>    0.0004</td> <td>    0.070</td> <td>    0.006</td> <td> 0.995</td> <td>   -0.136</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_home_speaker</th>             <td>    0.2569</td> <td>    0.583</td> <td>    0.441</td> <td> 0.660</td> <td>   -0.886</td> <td>    1.400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_home_spoken</th>              <td>   -0.5812</td> <td>    0.597</td> <td>   -0.974</td> <td> 0.330</td> <td>   -1.751</td> <td>    0.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_continue</th>     <td>   -0.0557</td> <td>    0.082</td> <td>   -0.683</td> <td> 0.495</td> <td>   -0.216</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_encourage</th>    <td>   -0.2335</td> <td>    0.103</td> <td>   -2.263</td> <td> 0.024</td> <td>   -0.436</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_stressed</th>     <td>    0.0402</td> <td>    0.067</td> <td>    0.603</td> <td> 0.547</td> <td>   -0.091</td> <td>    0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_important</th>    <td>    0.1564</td> <td>    0.123</td> <td>    1.267</td> <td> 0.205</td> <td>   -0.085</td> <td>    0.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_required</th>            <td>    0.0032</td> <td>    0.047</td> <td>    0.067</td> <td> 0.946</td> <td>   -0.089</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_choose_not</th>          <td>   -0.0521</td> <td>    0.079</td> <td>   -0.660</td> <td> 0.509</td> <td>   -0.207</td> <td>    0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_nervous</th>             <td>   -0.0407</td> <td>    0.061</td> <td>   -0.670</td> <td> 0.503</td> <td>   -0.160</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_difficult</th>           <td>   -0.0526</td> <td>    0.068</td> <td>   -0.777</td> <td> 0.437</td> <td>   -0.185</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_newspapers</th>          <td>   -0.0831</td> <td>    0.076</td> <td>   -1.098</td> <td> 0.272</td> <td>   -0.231</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_tv</th>                  <td>   -0.0571</td> <td>    0.071</td> <td>   -0.802</td> <td> 0.422</td> <td>   -0.197</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_understand</th>          <td>    0.0595</td> <td>    0.065</td> <td>    0.920</td> <td> 0.358</td> <td>   -0.067</td> <td>    0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_speak</th>               <td>    0.2172</td> <td>    0.106</td> <td>    2.050</td> <td> 0.040</td> <td>    0.010</td> <td>    0.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_many</th>                <td>   -0.1402</td> <td>    0.087</td> <td>   -1.617</td> <td> 0.106</td> <td>   -0.310</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_practical</th>           <td>   -0.0360</td> <td>    0.075</td> <td>   -0.481</td> <td> 0.631</td> <td>   -0.183</td> <td>    0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_career</th>              <td>    0.1225</td> <td>    0.074</td> <td>    1.665</td> <td> 0.096</td> <td>   -0.022</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_job</th>                 <td>    0.0801</td> <td>    0.075</td> <td>    1.070</td> <td> 0.285</td> <td>   -0.067</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_educated</th>            <td>    0.2286</td> <td>    0.132</td> <td>    1.732</td> <td> 0.083</td> <td>   -0.030</td> <td>    0.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_converse</th>            <td>   -0.0509</td> <td>    0.135</td> <td>   -0.376</td> <td> 0.707</td> <td>   -0.316</td> <td>    0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_understand_cultural</th> <td>    0.2215</td> <td>    0.117</td> <td>    1.898</td> <td> 0.058</td> <td>   -0.007</td> <td>    0.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_interact</th>            <td>    0.0495</td> <td>    0.108</td> <td>    0.457</td> <td> 0.647</td> <td>   -0.163</td> <td>    0.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_great</th>               <td>    0.0703</td> <td>    0.135</td> <td>    0.519</td> <td> 0.604</td> <td>   -0.195</td> <td>    0.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_communicate</th>         <td>    0.0964</td> <td>    0.102</td> <td>    0.946</td> <td> 0.344</td> <td>   -0.103</td> <td>    0.296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_natural</th>             <td>   -0.0876</td> <td>    0.132</td> <td>   -0.663</td> <td> 0.507</td> <td>   -0.347</td> <td>    0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_fluent</th>              <td>   -0.2305</td> <td>    0.138</td> <td>   -1.675</td> <td> 0.094</td> <td>   -0.500</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_aspects</th>             <td>   -0.0838</td> <td>    0.118</td> <td>   -0.712</td> <td> 0.477</td> <td>   -0.315</td> <td>    0.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_choose</th>              <td>    0.1258</td> <td>    0.072</td> <td>    1.736</td> <td> 0.082</td> <td>   -0.016</td> <td>    0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_friends</th>             <td>   -0.1696</td> <td>    0.090</td> <td>   -1.893</td> <td> 0.058</td> <td>   -0.345</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_read</th>                <td>    0.0269</td> <td>    0.067</td> <td>    0.402</td> <td> 0.688</td> <td>   -0.104</td> <td>    0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_family</th>                   <td>    0.0953</td> <td>  147.197</td> <td>    0.001</td> <td> 0.999</td> <td> -288.405</td> <td>  288.596</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_education</th>                <td>   -0.3516</td> <td>  147.197</td> <td>   -0.002</td> <td> 0.998</td> <td> -288.852</td> <td>  288.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_media</th>                    <td>    0.2574</td> <td>  147.197</td> <td>    0.002</td> <td> 0.999</td> <td> -288.243</td> <td>  288.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_improvement</th>              <td>    0.0965</td> <td>  147.197</td> <td>    0.001</td> <td> 0.999</td> <td> -288.404</td> <td>  288.597</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_culture</th>                  <td>    0.1794</td> <td>  147.197</td> <td>    0.001</td> <td> 0.999</td> <td> -288.321</td> <td>  288.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_citizenship</th>              <td>   -0.1607</td> <td>  147.197</td> <td>   -0.001</td> <td> 0.999</td> <td> -288.661</td> <td>  288.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Never/Rarely</th>                  <td>   -1.7223</td> <td> 3091.129</td> <td>   -0.001</td> <td> 1.000</td> <td>-6060.224</td> <td> 6056.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rarely/Infrequently</th>           <td>   -0.9296</td> <td>    0.560</td> <td>   -1.659</td> <td> 0.097</td> <td>   -2.028</td> <td>    0.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Infrequently/Occassionally</th>    <td>   -0.7094</td> <td>    0.424</td> <td>   -1.672</td> <td> 0.095</td> <td>   -1.541</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Occassionally/Sometimes</th>       <td>   -0.0095</td> <td>    0.228</td> <td>   -0.042</td> <td> 0.967</td> <td>   -0.456</td> <td>    0.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sometimes/Often</th>               <td>    0.3885</td> <td>    0.155</td> <td>    2.509</td> <td> 0.012</td> <td>    0.085</td> <td>    0.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Often/Very Often</th>              <td>    0.2104</td> <td>    0.193</td> <td>    1.091</td> <td> 0.275</td> <td>   -0.168</td> <td>    0.588</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                               OrderedModel Results                               \n",
       "==================================================================================\n",
       "Dep. Variable:     engage_practice_others   Log-Likelihood:                -116.96\n",
       "Model:                       OrderedModel   AIC:                             321.9\n",
       "Method:                Maximum Likelihood   BIC:                             433.3\n",
       "Date:                    Mon, 12 Jun 2023                                         \n",
       "Time:                            14:41:32                                         \n",
       "No. Observations:                      93                                         \n",
       "Df Residuals:                          49                                         \n",
       "Df Model:                              44                                         \n",
       "=================================================================================================\n",
       "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "demo_num_lang                    -0.4986      0.220     -2.262      0.024      -0.931      -0.067\n",
       "demo_years_learning               0.0004      0.070      0.006      0.995      -0.136       0.137\n",
       "demo_home_speaker                 0.2569      0.583      0.441      0.660      -0.886       1.400\n",
       "demo_home_spoken                 -0.5812      0.597     -0.974      0.330      -1.751       0.589\n",
       "motivator_family_continue        -0.0557      0.082     -0.683      0.495      -0.216       0.104\n",
       "motivator_family_encourage       -0.2335      0.103     -2.263      0.024      -0.436      -0.031\n",
       "motivator_family_stressed         0.0402      0.067      0.603      0.547      -0.091       0.171\n",
       "motivator_family_important        0.1564      0.123      1.267      0.205      -0.085       0.398\n",
       "motivator_required                0.0032      0.047      0.067      0.946      -0.089       0.095\n",
       "motivator_choose_not             -0.0521      0.079     -0.660      0.509      -0.207       0.103\n",
       "motivator_nervous                -0.0407      0.061     -0.670      0.503      -0.160       0.078\n",
       "motivator_difficult              -0.0526      0.068     -0.777      0.437      -0.185       0.080\n",
       "motivator_newspapers             -0.0831      0.076     -1.098      0.272      -0.231       0.065\n",
       "motivator_tv                     -0.0571      0.071     -0.802      0.422      -0.197       0.082\n",
       "motivator_understand              0.0595      0.065      0.920      0.358      -0.067       0.186\n",
       "motivator_speak                   0.2172      0.106      2.050      0.040       0.010       0.425\n",
       "motivator_many                   -0.1402      0.087     -1.617      0.106      -0.310       0.030\n",
       "motivator_practical              -0.0360      0.075     -0.481      0.631      -0.183       0.111\n",
       "motivator_career                  0.1225      0.074      1.665      0.096      -0.022       0.267\n",
       "motivator_job                     0.0801      0.075      1.070      0.285      -0.067       0.227\n",
       "motivator_educated                0.2286      0.132      1.732      0.083      -0.030       0.487\n",
       "motivator_converse               -0.0509      0.135     -0.376      0.707      -0.316       0.215\n",
       "motivator_understand_cultural     0.2215      0.117      1.898      0.058      -0.007       0.450\n",
       "motivator_interact                0.0495      0.108      0.457      0.647      -0.163       0.262\n",
       "motivator_great                   0.0703      0.135      0.519      0.604      -0.195       0.335\n",
       "motivator_communicate             0.0964      0.102      0.946      0.344      -0.103       0.296\n",
       "motivator_natural                -0.0876      0.132     -0.663      0.507      -0.347       0.171\n",
       "motivator_fluent                 -0.2305      0.138     -1.675      0.094      -0.500       0.039\n",
       "motivator_aspects                -0.0838      0.118     -0.712      0.477      -0.315       0.147\n",
       "motivator_choose                  0.1258      0.072      1.736      0.082      -0.016       0.268\n",
       "motivator_friends                -0.1696      0.090     -1.893      0.058      -0.345       0.006\n",
       "motivator_read                    0.0269      0.067      0.402      0.688      -0.104       0.158\n",
       "rank_family                       0.0953    147.197      0.001      0.999    -288.405     288.596\n",
       "rank_education                   -0.3516    147.197     -0.002      0.998    -288.852     288.149\n",
       "rank_media                        0.2574    147.197      0.002      0.999    -288.243     288.757\n",
       "rank_improvement                  0.0965    147.197      0.001      0.999    -288.404     288.597\n",
       "rank_culture                      0.1794    147.197      0.001      0.999    -288.321     288.680\n",
       "rank_citizenship                 -0.1607    147.197     -0.001      0.999    -288.661     288.339\n",
       "Never/Rarely                     -1.7223   3091.129     -0.001      1.000   -6060.224    6056.779\n",
       "Rarely/Infrequently              -0.9296      0.560     -1.659      0.097      -2.028       0.168\n",
       "Infrequently/Occassionally       -0.7094      0.424     -1.672      0.095      -1.541       0.122\n",
       "Occassionally/Sometimes          -0.0095      0.228     -0.042      0.967      -0.456       0.437\n",
       "Sometimes/Often                   0.3885      0.155      2.509      0.012       0.085       0.692\n",
       "Often/Very Often                  0.2104      0.193      1.091      0.275      -0.168       0.588\n",
       "=================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OrderedModel.from_formula(ordered_formula, engage_df, hasconst=False).fit(method='bfgs')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quach\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\miscmodels\\ordinal_model.py:373: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(np.diff(params[:-1]))))\n",
      "c:\\Users\\quach\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tools\\numdiff.py:157: RuntimeWarning: invalid value encountered in add\n",
      "  grad[k, :] = (f(*((x+ei,)+args), **kwargs) -\n",
      "c:\\Users\\quach\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tools\\numdiff.py:447: RuntimeWarning: invalid value encountered in add\n",
      "  hess[i, j] = (f(*((x + ee[i, :] + ee[j, :],) + args), **kwargs)\n",
      "c:\\Users\\quach\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tools\\numdiff.py:449: RuntimeWarning: invalid value encountered in add\n",
      "  - (f(*((x - ee[i, :] + ee[j, :],) + args), **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: NaN result encountered.\n",
      "         Current function value: 0.500285\n",
      "         Iterations: 0\n",
      "         Function evaluations: 1\n",
      "         Gradient evaluations: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quach\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tools\\numdiff.py:448: RuntimeWarning: invalid value encountered in add\n",
      "  - f(*((x + ee[i, :] - ee[j, :],) + args), **kwargs)\n",
      "c:\\Users\\quach\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:592: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warnings.warn('Inverting hessian failed, no bse or cov_params '\n",
      "c:\\Users\\quach\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\quach\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\miscmodels\\ordinal_model.py:373: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(np.diff(params[:-1]))))\n",
      "c:\\Users\\quach\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tools\\numdiff.py:157: RuntimeWarning: invalid value encountered in add\n",
      "  grad[k, :] = (f(*((x+ei,)+args), **kwargs) -\n",
      "c:\\Users\\quach\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tools\\numdiff.py:447: RuntimeWarning: invalid value encountered in add\n",
      "  hess[i, j] = (f(*((x + ee[i, :] + ee[j, :],) + args), **kwargs)\n",
      "c:\\Users\\quach\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tools\\numdiff.py:449: RuntimeWarning: invalid value encountered in add\n",
      "  - (f(*((x - ee[i, :] + ee[j, :],) + args), **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: NaN result encountered.\n",
      "         Current function value: 1.118372\n",
      "         Iterations: 0\n",
      "         Function evaluations: 1\n",
      "         Gradient evaluations: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quach\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tools\\numdiff.py:448: RuntimeWarning: invalid value encountered in add\n",
      "  - f(*((x + ee[i, :] - ee[j, :],) + args), **kwargs)\n",
      "c:\\Users\\quach\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:592: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warnings.warn('Inverting hessian failed, no bse or cov_params '\n",
      "c:\\Users\\quach\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.471434\n",
      "         Iterations: 55\n",
      "         Function evaluations: 59\n",
      "         Gradient evaluations: 59\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.257521\n",
      "         Iterations: 58\n",
      "         Function evaluations: 63\n",
      "         Gradient evaluations: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quach\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:592: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warnings.warn('Inverting hessian failed, no bse or cov_params '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.488765\n",
      "         Iterations: 58\n",
      "         Function evaluations: 63\n",
      "         Gradient evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.634311\n",
      "         Iterations: 50\n",
      "         Function evaluations: 55\n",
      "         Gradient evaluations: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quach\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:592: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warnings.warn('Inverting hessian failed, no bse or cov_params '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.439855\n",
      "         Iterations: 52\n",
      "         Function evaluations: 56\n",
      "         Gradient evaluations: 56\n"
     ]
    }
   ],
   "source": [
    "# Create an ordered model with the engagement columns as dependent and full model as the independent\n",
    "engage_models = []\n",
    "\n",
    "for col in engage_cols:\n",
    "    formula = col + ' ~ 1 +' + ' + '.join(full_cols) + ' + ' + ' + '.join(rank_only) + ' + ' + controlling\n",
    "    model = OrderedModel.from_formula(formula, engage_df, hasconst=False, distr='logit').fit(method='bfgs')\n",
    "    # Check to see if any of the p-values for the motives are less than 0.05\n",
    "    if any(model.pvalues[0:-10] < 0.05):\n",
    "        engage_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(engage_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OrderedModel Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>engage_listen</td>   <th>  Log-Likelihood:    </th> <td> -138.46</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>OrderedModel</td>    <th>  AIC:               </th> <td>   364.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>           <td>Maximum Likelihood</td> <th>  BIC:               </th> <td>   476.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 12 Jun 2023</td>  <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>14:54:26</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>    93</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>    49</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    44</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_continue</th>     <td>   -0.1711</td> <td>    0.138</td> <td>   -1.239</td> <td> 0.215</td> <td>   -0.442</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_encourage</th>    <td>   -0.3705</td> <td>    0.172</td> <td>   -2.157</td> <td> 0.031</td> <td>   -0.707</td> <td>   -0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_stressed</th>     <td>    0.1949</td> <td>    0.117</td> <td>    1.669</td> <td> 0.095</td> <td>   -0.034</td> <td>    0.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_important</th>    <td>    0.0703</td> <td>    0.205</td> <td>    0.342</td> <td> 0.732</td> <td>   -0.332</td> <td>    0.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_required</th>            <td>    0.0470</td> <td>    0.082</td> <td>    0.571</td> <td> 0.568</td> <td>   -0.114</td> <td>    0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_choose_not</th>          <td>   -0.1454</td> <td>    0.137</td> <td>   -1.058</td> <td> 0.290</td> <td>   -0.415</td> <td>    0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_nervous</th>             <td>    0.1397</td> <td>    0.107</td> <td>    1.303</td> <td> 0.193</td> <td>   -0.070</td> <td>    0.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_difficult</th>           <td>   -0.0091</td> <td>    0.122</td> <td>   -0.075</td> <td> 0.940</td> <td>   -0.248</td> <td>    0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_newspapers</th>          <td>   -0.2574</td> <td>    0.127</td> <td>   -2.030</td> <td> 0.042</td> <td>   -0.506</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_tv</th>                  <td>   -0.0659</td> <td>    0.118</td> <td>   -0.557</td> <td> 0.577</td> <td>   -0.298</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_understand</th>          <td>    0.2239</td> <td>    0.107</td> <td>    2.087</td> <td> 0.037</td> <td>    0.014</td> <td>    0.434</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_speak</th>               <td>    0.4313</td> <td>    0.175</td> <td>    2.470</td> <td> 0.014</td> <td>    0.089</td> <td>    0.773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_many</th>                <td>    0.0548</td> <td>    0.144</td> <td>    0.380</td> <td> 0.704</td> <td>   -0.227</td> <td>    0.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_practical</th>           <td>    0.0187</td> <td>    0.129</td> <td>    0.145</td> <td> 0.884</td> <td>   -0.233</td> <td>    0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_career</th>              <td>    0.4104</td> <td>    0.126</td> <td>    3.266</td> <td> 0.001</td> <td>    0.164</td> <td>    0.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_job</th>                 <td>    0.1029</td> <td>    0.126</td> <td>    0.817</td> <td> 0.414</td> <td>   -0.144</td> <td>    0.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_educated</th>            <td>    0.0438</td> <td>    0.227</td> <td>    0.193</td> <td> 0.847</td> <td>   -0.401</td> <td>    0.489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_converse</th>            <td>   -0.2443</td> <td>    0.248</td> <td>   -0.984</td> <td> 0.325</td> <td>   -0.731</td> <td>    0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_understand_cultural</th> <td>    0.1351</td> <td>    0.201</td> <td>    0.674</td> <td> 0.501</td> <td>   -0.258</td> <td>    0.528</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_interact</th>            <td>   -0.1300</td> <td>    0.199</td> <td>   -0.654</td> <td> 0.513</td> <td>   -0.519</td> <td>    0.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_great</th>               <td>   -0.2460</td> <td>    0.240</td> <td>   -1.026</td> <td> 0.305</td> <td>   -0.716</td> <td>    0.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_communicate</th>         <td>    0.1334</td> <td>    0.175</td> <td>    0.764</td> <td> 0.445</td> <td>   -0.209</td> <td>    0.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_natural</th>             <td>   -0.0939</td> <td>    0.235</td> <td>   -0.399</td> <td> 0.690</td> <td>   -0.555</td> <td>    0.367</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_fluent</th>              <td>   -0.4270</td> <td>    0.230</td> <td>   -1.858</td> <td> 0.063</td> <td>   -0.878</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_aspects</th>             <td>    0.3600</td> <td>    0.197</td> <td>    1.824</td> <td> 0.068</td> <td>   -0.027</td> <td>    0.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_choose</th>              <td>    0.1195</td> <td>    0.119</td> <td>    1.003</td> <td> 0.316</td> <td>   -0.114</td> <td>    0.353</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_friends</th>             <td>   -0.3265</td> <td>    0.161</td> <td>   -2.034</td> <td> 0.042</td> <td>   -0.641</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_read</th>                <td>    0.0630</td> <td>    0.121</td> <td>    0.519</td> <td> 0.604</td> <td>   -0.175</td> <td>    0.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_family</th>                   <td>    0.1918</td> <td>   87.863</td> <td>    0.002</td> <td> 0.998</td> <td> -172.016</td> <td>  172.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_education</th>                <td>   -0.6651</td> <td>   87.863</td> <td>   -0.008</td> <td> 0.994</td> <td> -172.873</td> <td>  171.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_media</th>                    <td>    0.6383</td> <td>   87.863</td> <td>    0.007</td> <td> 0.994</td> <td> -171.570</td> <td>  172.846</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_improvement</th>              <td>    0.1877</td> <td>   87.863</td> <td>    0.002</td> <td> 0.998</td> <td> -172.020</td> <td>  172.395</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_culture</th>                  <td>    0.2231</td> <td>   87.863</td> <td>    0.003</td> <td> 0.998</td> <td> -171.985</td> <td>  172.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_citizenship</th>              <td>   -0.0573</td> <td>   87.863</td> <td>   -0.001</td> <td> 0.999</td> <td> -172.266</td> <td>  172.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_num_lang</th>                 <td>   -0.5212</td> <td>    0.401</td> <td>   -1.298</td> <td> 0.194</td> <td>   -1.308</td> <td>    0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_years_learning</th>           <td>   -0.0407</td> <td>    0.120</td> <td>   -0.338</td> <td> 0.735</td> <td>   -0.277</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_home_speaker</th>             <td>   -0.4859</td> <td>    1.033</td> <td>   -0.470</td> <td> 0.638</td> <td>   -2.511</td> <td>    1.539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_home_spoken</th>              <td>    1.1333</td> <td>    1.059</td> <td>    1.070</td> <td> 0.285</td> <td>   -0.943</td> <td>    3.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Never/Rarely</th>                  <td>   -3.1270</td> <td> 1845.114</td> <td>   -0.002</td> <td> 0.999</td> <td>-3619.484</td> <td> 3613.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rarely/Infrequently</th>           <td>   -0.4030</td> <td>    0.570</td> <td>   -0.707</td> <td> 0.480</td> <td>   -1.521</td> <td>    0.715</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Infrequently/Occassionally</th>    <td>    0.2266</td> <td>    0.303</td> <td>    0.748</td> <td> 0.454</td> <td>   -0.367</td> <td>    0.820</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Occassionally/Sometimes</th>       <td>    0.4608</td> <td>    0.208</td> <td>    2.217</td> <td> 0.027</td> <td>    0.054</td> <td>    0.868</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sometimes/Often</th>               <td>    0.2656</td> <td>    0.210</td> <td>    1.265</td> <td> 0.206</td> <td>   -0.146</td> <td>    0.677</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Often/Very Often</th>              <td>    0.4744</td> <td>    0.208</td> <td>    2.278</td> <td> 0.023</td> <td>    0.066</td> <td>    0.883</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                             OrderedModel Results                             \n",
       "==============================================================================\n",
       "Dep. Variable:          engage_listen   Log-Likelihood:                -138.46\n",
       "Model:                   OrderedModel   AIC:                             364.9\n",
       "Method:            Maximum Likelihood   BIC:                             476.3\n",
       "Date:                Mon, 12 Jun 2023                                         \n",
       "Time:                        14:54:26                                         \n",
       "No. Observations:                  93                                         \n",
       "Df Residuals:                      49                                         \n",
       "Df Model:                          44                                         \n",
       "=================================================================================================\n",
       "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "motivator_family_continue        -0.1711      0.138     -1.239      0.215      -0.442       0.100\n",
       "motivator_family_encourage       -0.3705      0.172     -2.157      0.031      -0.707      -0.034\n",
       "motivator_family_stressed         0.1949      0.117      1.669      0.095      -0.034       0.424\n",
       "motivator_family_important        0.0703      0.205      0.342      0.732      -0.332       0.473\n",
       "motivator_required                0.0470      0.082      0.571      0.568      -0.114       0.208\n",
       "motivator_choose_not             -0.1454      0.137     -1.058      0.290      -0.415       0.124\n",
       "motivator_nervous                 0.1397      0.107      1.303      0.193      -0.070       0.350\n",
       "motivator_difficult              -0.0091      0.122     -0.075      0.940      -0.248       0.230\n",
       "motivator_newspapers             -0.2574      0.127     -2.030      0.042      -0.506      -0.009\n",
       "motivator_tv                     -0.0659      0.118     -0.557      0.577      -0.298       0.166\n",
       "motivator_understand              0.2239      0.107      2.087      0.037       0.014       0.434\n",
       "motivator_speak                   0.4313      0.175      2.470      0.014       0.089       0.773\n",
       "motivator_many                    0.0548      0.144      0.380      0.704      -0.227       0.337\n",
       "motivator_practical               0.0187      0.129      0.145      0.884      -0.233       0.271\n",
       "motivator_career                  0.4104      0.126      3.266      0.001       0.164       0.657\n",
       "motivator_job                     0.1029      0.126      0.817      0.414      -0.144       0.350\n",
       "motivator_educated                0.0438      0.227      0.193      0.847      -0.401       0.489\n",
       "motivator_converse               -0.2443      0.248     -0.984      0.325      -0.731       0.242\n",
       "motivator_understand_cultural     0.1351      0.201      0.674      0.501      -0.258       0.528\n",
       "motivator_interact               -0.1300      0.199     -0.654      0.513      -0.519       0.259\n",
       "motivator_great                  -0.2460      0.240     -1.026      0.305      -0.716       0.224\n",
       "motivator_communicate             0.1334      0.175      0.764      0.445      -0.209       0.476\n",
       "motivator_natural                -0.0939      0.235     -0.399      0.690      -0.555       0.367\n",
       "motivator_fluent                 -0.4270      0.230     -1.858      0.063      -0.878       0.023\n",
       "motivator_aspects                 0.3600      0.197      1.824      0.068      -0.027       0.747\n",
       "motivator_choose                  0.1195      0.119      1.003      0.316      -0.114       0.353\n",
       "motivator_friends                -0.3265      0.161     -2.034      0.042      -0.641      -0.012\n",
       "motivator_read                    0.0630      0.121      0.519      0.604      -0.175       0.301\n",
       "rank_family                       0.1918     87.863      0.002      0.998    -172.016     172.399\n",
       "rank_education                   -0.6651     87.863     -0.008      0.994    -172.873     171.543\n",
       "rank_media                        0.6383     87.863      0.007      0.994    -171.570     172.846\n",
       "rank_improvement                  0.1877     87.863      0.002      0.998    -172.020     172.395\n",
       "rank_culture                      0.2231     87.863      0.003      0.998    -171.985     172.431\n",
       "rank_citizenship                 -0.0573     87.863     -0.001      0.999    -172.266     172.151\n",
       "demo_num_lang                    -0.5212      0.401     -1.298      0.194      -1.308       0.266\n",
       "demo_years_learning              -0.0407      0.120     -0.338      0.735      -0.277       0.195\n",
       "demo_home_speaker                -0.4859      1.033     -0.470      0.638      -2.511       1.539\n",
       "demo_home_spoken                  1.1333      1.059      1.070      0.285      -0.943       3.210\n",
       "Never/Rarely                     -3.1270   1845.114     -0.002      0.999   -3619.484    3613.230\n",
       "Rarely/Infrequently              -0.4030      0.570     -0.707      0.480      -1.521       0.715\n",
       "Infrequently/Occassionally        0.2266      0.303      0.748      0.454      -0.367       0.820\n",
       "Occassionally/Sometimes           0.4608      0.208      2.217      0.027       0.054       0.868\n",
       "Sometimes/Often                   0.2656      0.210      1.265      0.206      -0.146       0.677\n",
       "Often/Very Often                  0.4744      0.208      2.278      0.023       0.066       0.883\n",
       "=================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engage_models[1].summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "---\n",
    "There appears to be no significant relationship between each motivator and how students engage with material."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final OLS\n",
    "---\n",
    "For the final series of linear regressions, we'll see how motivators affect how people use their languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns with 'use_' in the name\n",
    "use_cols = [col for col in df.columns if 'use_' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a temporary df which does not contain outliers\n",
    "temp_df = df.copy()\n",
    "\n",
    "# Remove outliers from the dataframe based on use_cols values\n",
    "for col in use_cols:\n",
    "    temp_df = temp_df[np.abs(temp_df[col] - temp_df[col].mean()) <= (3 * temp_df[col].std())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an OLS on the use_cols with the full model as the independent\n",
    "use_models = computeModel(use_cols, full_cols + rank_only, dataframe=temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(use_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>use_duolingo_usage</td> <th>  R-squared:         </th> <td>   0.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   1.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 12 Jun 2023</td>  <th>  Prob (F-statistic):</th>  <td> 0.133</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>14:06:27</td>      <th>  Log-Likelihood:    </th> <td> -260.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>    82</td>       <th>  AIC:               </th> <td>   598.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>    44</td>       <th>  BIC:               </th> <td>   689.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    37</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                     <td>    0.0428</td> <td>    0.152</td> <td>    0.281</td> <td> 0.780</td> <td>   -0.264</td> <td>    0.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_continue</th>     <td>   -0.3759</td> <td>    0.749</td> <td>   -0.502</td> <td> 0.618</td> <td>   -1.885</td> <td>    1.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_encourage</th>    <td>    0.4956</td> <td>    0.841</td> <td>    0.589</td> <td> 0.559</td> <td>   -1.200</td> <td>    2.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_stressed</th>     <td>   -0.7902</td> <td>    0.550</td> <td>   -1.436</td> <td> 0.158</td> <td>   -1.899</td> <td>    0.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_important</th>    <td>    1.0448</td> <td>    1.114</td> <td>    0.938</td> <td> 0.354</td> <td>   -1.201</td> <td>    3.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_required</th>            <td>   -0.1321</td> <td>    0.374</td> <td>   -0.353</td> <td> 0.726</td> <td>   -0.886</td> <td>    0.622</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_choose_not</th>          <td>   -0.4103</td> <td>    0.638</td> <td>   -0.643</td> <td> 0.523</td> <td>   -1.696</td> <td>    0.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_nervous</th>             <td>    0.5926</td> <td>    0.501</td> <td>    1.182</td> <td> 0.244</td> <td>   -0.418</td> <td>    1.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_difficult</th>           <td>    0.0340</td> <td>    0.571</td> <td>    0.060</td> <td> 0.953</td> <td>   -1.116</td> <td>    1.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_newspapers</th>          <td>    0.4090</td> <td>    0.637</td> <td>    0.642</td> <td> 0.524</td> <td>   -0.874</td> <td>    1.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_tv</th>                  <td>   -0.2226</td> <td>    0.583</td> <td>   -0.382</td> <td> 0.704</td> <td>   -1.397</td> <td>    0.952</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_understand</th>          <td>   -0.4987</td> <td>    0.569</td> <td>   -0.877</td> <td> 0.386</td> <td>   -1.645</td> <td>    0.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_speak</th>               <td>    0.7329</td> <td>    0.828</td> <td>    0.885</td> <td> 0.381</td> <td>   -0.937</td> <td>    2.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_many</th>                <td>   -1.7639</td> <td>    0.710</td> <td>   -2.484</td> <td> 0.017</td> <td>   -3.195</td> <td>   -0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_practical</th>           <td>    0.2515</td> <td>    0.602</td> <td>    0.418</td> <td> 0.678</td> <td>   -0.961</td> <td>    1.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_career</th>              <td>    0.8396</td> <td>    0.607</td> <td>    1.384</td> <td> 0.173</td> <td>   -0.383</td> <td>    2.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_job</th>                 <td>   -0.9933</td> <td>    0.596</td> <td>   -1.667</td> <td> 0.103</td> <td>   -2.194</td> <td>    0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_educated</th>            <td>   -0.3875</td> <td>    1.080</td> <td>   -0.359</td> <td> 0.721</td> <td>   -2.564</td> <td>    1.789</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_converse</th>            <td>   -2.1712</td> <td>    1.072</td> <td>   -2.026</td> <td> 0.049</td> <td>   -4.331</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_understand_cultural</th> <td>    1.5134</td> <td>    0.889</td> <td>    1.702</td> <td> 0.096</td> <td>   -0.279</td> <td>    3.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_interact</th>            <td>    1.5799</td> <td>    0.823</td> <td>    1.919</td> <td> 0.062</td> <td>   -0.080</td> <td>    3.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_great</th>               <td>    1.0235</td> <td>    1.055</td> <td>    0.970</td> <td> 0.337</td> <td>   -1.104</td> <td>    3.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_communicate</th>         <td>   -1.3767</td> <td>    0.821</td> <td>   -1.678</td> <td> 0.101</td> <td>   -3.031</td> <td>    0.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_natural</th>             <td>   -0.9457</td> <td>    1.015</td> <td>   -0.932</td> <td> 0.357</td> <td>   -2.992</td> <td>    1.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_fluent</th>              <td>   -0.5238</td> <td>    1.025</td> <td>   -0.511</td> <td> 0.612</td> <td>   -2.589</td> <td>    1.542</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_aspects</th>             <td>    0.6980</td> <td>    0.951</td> <td>    0.734</td> <td> 0.467</td> <td>   -1.218</td> <td>    2.614</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_choose</th>              <td>    0.4453</td> <td>    0.674</td> <td>    0.660</td> <td> 0.513</td> <td>   -0.914</td> <td>    1.804</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_friends</th>             <td>    0.1039</td> <td>    0.726</td> <td>    0.143</td> <td> 0.887</td> <td>   -1.358</td> <td>    1.566</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_read</th>                <td>    0.3505</td> <td>    0.547</td> <td>    0.640</td> <td> 0.525</td> <td>   -0.753</td> <td>    1.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_family</th>                   <td>   -0.4512</td> <td>    0.846</td> <td>   -0.533</td> <td> 0.596</td> <td>   -2.156</td> <td>    1.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_education</th>                <td>   -0.2231</td> <td>    1.113</td> <td>   -0.200</td> <td> 0.842</td> <td>   -2.466</td> <td>    2.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_media</th>                    <td>    1.3755</td> <td>    1.029</td> <td>    1.337</td> <td> 0.188</td> <td>   -0.698</td> <td>    3.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_improvement</th>              <td>    1.9187</td> <td>    0.821</td> <td>    2.337</td> <td> 0.024</td> <td>    0.264</td> <td>    3.573</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_culture</th>                  <td>   -1.1651</td> <td>    1.140</td> <td>   -1.022</td> <td> 0.312</td> <td>   -3.462</td> <td>    1.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_citizenship</th>              <td>   -0.5566</td> <td>    1.060</td> <td>   -0.525</td> <td> 0.602</td> <td>   -2.692</td> <td>    1.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_num_lang</th>                 <td>    2.9737</td> <td>    1.765</td> <td>    1.684</td> <td> 0.099</td> <td>   -0.584</td> <td>    6.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_years_learning</th>           <td>   -0.3437</td> <td>    0.613</td> <td>   -0.561</td> <td> 0.578</td> <td>   -1.578</td> <td>    0.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_home_speaker</th>             <td>   -6.8386</td> <td>    4.831</td> <td>   -1.416</td> <td> 0.164</td> <td>  -16.575</td> <td>    2.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_home_spoken</th>              <td>    0.9066</td> <td>    4.729</td> <td>    0.192</td> <td> 0.849</td> <td>   -8.623</td> <td>   10.437</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.812</td> <th>  Durbin-Watson:     </th> <td>   2.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.090</td> <th>  Jarque-Bera (JB):  </th> <td>   4.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.514</td> <th>  Prob(JB):          </th> <td>   0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.369</td> <th>  Cond. No.          </th> <td>2.90e+17</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.47e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     use_duolingo_usage   R-squared:                       0.544\n",
       "Model:                            OLS   Adj. R-squared:                  0.160\n",
       "Method:                 Least Squares   F-statistic:                     1.419\n",
       "Date:                Mon, 12 Jun 2023   Prob (F-statistic):              0.133\n",
       "Time:                        14:06:27   Log-Likelihood:                -260.99\n",
       "No. Observations:                  82   AIC:                             598.0\n",
       "Df Residuals:                      44   BIC:                             689.4\n",
       "Df Model:                          37                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================================\n",
       "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "Intercept                         0.0428      0.152      0.281      0.780      -0.264       0.350\n",
       "motivator_family_continue        -0.3759      0.749     -0.502      0.618      -1.885       1.133\n",
       "motivator_family_encourage        0.4956      0.841      0.589      0.559      -1.200       2.191\n",
       "motivator_family_stressed        -0.7902      0.550     -1.436      0.158      -1.899       0.319\n",
       "motivator_family_important        1.0448      1.114      0.938      0.354      -1.201       3.290\n",
       "motivator_required               -0.1321      0.374     -0.353      0.726      -0.886       0.622\n",
       "motivator_choose_not             -0.4103      0.638     -0.643      0.523      -1.696       0.875\n",
       "motivator_nervous                 0.5926      0.501      1.182      0.244      -0.418       1.603\n",
       "motivator_difficult               0.0340      0.571      0.060      0.953      -1.116       1.184\n",
       "motivator_newspapers              0.4090      0.637      0.642      0.524      -0.874       1.692\n",
       "motivator_tv                     -0.2226      0.583     -0.382      0.704      -1.397       0.952\n",
       "motivator_understand             -0.4987      0.569     -0.877      0.386      -1.645       0.648\n",
       "motivator_speak                   0.7329      0.828      0.885      0.381      -0.937       2.403\n",
       "motivator_many                   -1.7639      0.710     -2.484      0.017      -3.195      -0.333\n",
       "motivator_practical               0.2515      0.602      0.418      0.678      -0.961       1.464\n",
       "motivator_career                  0.8396      0.607      1.384      0.173      -0.383       2.063\n",
       "motivator_job                    -0.9933      0.596     -1.667      0.103      -2.194       0.208\n",
       "motivator_educated               -0.3875      1.080     -0.359      0.721      -2.564       1.789\n",
       "motivator_converse               -2.1712      1.072     -2.026      0.049      -4.331      -0.011\n",
       "motivator_understand_cultural     1.5134      0.889      1.702      0.096      -0.279       3.306\n",
       "motivator_interact                1.5799      0.823      1.919      0.062      -0.080       3.239\n",
       "motivator_great                   1.0235      1.055      0.970      0.337      -1.104       3.151\n",
       "motivator_communicate            -1.3767      0.821     -1.678      0.101      -3.031       0.277\n",
       "motivator_natural                -0.9457      1.015     -0.932      0.357      -2.992       1.100\n",
       "motivator_fluent                 -0.5238      1.025     -0.511      0.612      -2.589       1.542\n",
       "motivator_aspects                 0.6980      0.951      0.734      0.467      -1.218       2.614\n",
       "motivator_choose                  0.4453      0.674      0.660      0.513      -0.914       1.804\n",
       "motivator_friends                 0.1039      0.726      0.143      0.887      -1.358       1.566\n",
       "motivator_read                    0.3505      0.547      0.640      0.525      -0.753       1.454\n",
       "rank_family                      -0.4512      0.846     -0.533      0.596      -2.156       1.254\n",
       "rank_education                   -0.2231      1.113     -0.200      0.842      -2.466       2.020\n",
       "rank_media                        1.3755      1.029      1.337      0.188      -0.698       3.449\n",
       "rank_improvement                  1.9187      0.821      2.337      0.024       0.264       3.573\n",
       "rank_culture                     -1.1651      1.140     -1.022      0.312      -3.462       1.132\n",
       "rank_citizenship                 -0.5566      1.060     -0.525      0.602      -2.692       1.579\n",
       "demo_num_lang                     2.9737      1.765      1.684      0.099      -0.584       6.532\n",
       "demo_years_learning              -0.3437      0.613     -0.561      0.578      -1.578       0.891\n",
       "demo_home_speaker                -6.8386      4.831     -1.416      0.164     -16.575       2.898\n",
       "demo_home_spoken                  0.9066      4.729      0.192      0.849      -8.623      10.437\n",
       "==============================================================================\n",
       "Omnibus:                        4.812   Durbin-Watson:                   2.047\n",
       "Prob(Omnibus):                  0.090   Jarque-Bera (JB):                4.072\n",
       "Skew:                           0.514   Prob(JB):                        0.131\n",
       "Kurtosis:                       3.369   Cond. No.                     2.90e+17\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.47e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_models[4].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the decode_dict.json file\n",
    "decode_dict = json.load(open('decode_dict.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I would really like to learn many foreign languages.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_dict['motivator_many']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Ordinal Logistic Regression\n",
    "--- \n",
    "We will conduct one last analysis which investigates how motivators affect student perception of their current and expected performance within a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns for 'feel_current_grade' and 'feel_expected_grade'\n",
    "grade_cols = ['feel_current_grade', 'feel_expected_grade']\n",
    "\n",
    "# Drop all rows which don't use A, B, C, D, or F\n",
    "grade_df = df.copy()\n",
    "grade_df = grade_df[grade_df['feel_current_grade'].isin(['A', 'B', 'C', 'D', 'F'])]\n",
    "grade_df = grade_df[grade_df['feel_expected_grade'].isin(['A', 'B', 'C', 'D', 'F'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feel_current_grade\n",
       "A    54\n",
       "B    28\n",
       "C     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_df['feel_current_grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feel_expected_grade\n",
       "A    54\n",
       "B    24\n",
       "C     6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_df['feel_expected_grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set an ordered categorical type for the grades\n",
    "grade_df['feel_current_grade'] = pd.Categorical(grade_df['feel_current_grade'], categories=['A', 'B', 'C'], ordered=True)\n",
    "\n",
    "grade_df['feel_expected_grade'] = pd.Categorical(grade_df['feel_expected_grade'], categories=['A', 'B', 'C'], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.258486\n",
      "         Iterations: 104\n",
      "         Function evaluations: 107\n",
      "         Gradient evaluations: 107\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OrderedModel Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>feel_current_grade</td> <th>  Log-Likelihood:    </th> <td> -21.713</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>OrderedModel</td>    <th>  AIC:               </th> <td>   123.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>           <td>Maximum Likelihood</td> <th>  BIC:               </th> <td>   220.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 12 Jun 2023</td>  <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>15:01:40</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>    84</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>    44</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    40</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_continue</th>     <td>    0.3639</td> <td>    0.324</td> <td>    1.122</td> <td> 0.262</td> <td>   -0.272</td> <td>    1.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_encourage</th>    <td>   -1.3226</td> <td>    0.745</td> <td>   -1.776</td> <td> 0.076</td> <td>   -2.782</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_stressed</th>     <td>   -0.3700</td> <td>    0.320</td> <td>   -1.158</td> <td> 0.247</td> <td>   -0.996</td> <td>    0.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_important</th>    <td>    0.7969</td> <td>    0.499</td> <td>    1.597</td> <td> 0.110</td> <td>   -0.181</td> <td>    1.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_required</th>            <td>    0.9357</td> <td>    0.581</td> <td>    1.609</td> <td> 0.108</td> <td>   -0.204</td> <td>    2.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_choose_not</th>          <td>   -1.3144</td> <td>    0.800</td> <td>   -1.643</td> <td> 0.100</td> <td>   -2.882</td> <td>    0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_nervous</th>             <td>    0.5947</td> <td>    0.419</td> <td>    1.421</td> <td> 0.155</td> <td>   -0.226</td> <td>    1.415</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_difficult</th>           <td>    1.5374</td> <td>    0.911</td> <td>    1.688</td> <td> 0.091</td> <td>   -0.248</td> <td>    3.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_newspapers</th>          <td>   -0.8395</td> <td>    0.465</td> <td>   -1.807</td> <td> 0.071</td> <td>   -1.750</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_tv</th>                  <td>    1.7224</td> <td>    0.965</td> <td>    1.785</td> <td> 0.074</td> <td>   -0.169</td> <td>    3.614</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_understand</th>          <td>    0.1639</td> <td>    0.294</td> <td>    0.558</td> <td> 0.577</td> <td>   -0.412</td> <td>    0.740</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_speak</th>               <td>    1.8990</td> <td>    1.074</td> <td>    1.768</td> <td> 0.077</td> <td>   -0.206</td> <td>    4.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_many</th>                <td>   -0.4268</td> <td>    0.380</td> <td>   -1.124</td> <td> 0.261</td> <td>   -1.171</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_practical</th>           <td>   -1.1088</td> <td>    0.643</td> <td>   -1.725</td> <td> 0.084</td> <td>   -2.368</td> <td>    0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_career</th>              <td>   -0.4025</td> <td>    0.305</td> <td>   -1.321</td> <td> 0.187</td> <td>   -1.000</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_job</th>                 <td>    1.7990</td> <td>    1.144</td> <td>    1.573</td> <td> 0.116</td> <td>   -0.442</td> <td>    4.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_educated</th>            <td>    1.1274</td> <td>    0.899</td> <td>    1.254</td> <td> 0.210</td> <td>   -0.635</td> <td>    2.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_converse</th>            <td>    0.5222</td> <td>    0.667</td> <td>    0.783</td> <td> 0.434</td> <td>   -0.786</td> <td>    1.830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_understand_cultural</th> <td>    1.4142</td> <td>    0.898</td> <td>    1.575</td> <td> 0.115</td> <td>   -0.346</td> <td>    3.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_interact</th>            <td>   -1.7965</td> <td>    1.089</td> <td>   -1.650</td> <td> 0.099</td> <td>   -3.930</td> <td>    0.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_great</th>               <td>    1.8368</td> <td>    1.051</td> <td>    1.748</td> <td> 0.080</td> <td>   -0.223</td> <td>    3.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_communicate</th>         <td>    1.1038</td> <td>    0.859</td> <td>    1.286</td> <td> 0.199</td> <td>   -0.579</td> <td>    2.786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_natural</th>             <td>   -1.7980</td> <td>    1.094</td> <td>   -1.643</td> <td> 0.100</td> <td>   -3.943</td> <td>    0.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_fluent</th>              <td>   -2.0639</td> <td>    1.393</td> <td>   -1.482</td> <td> 0.138</td> <td>   -4.793</td> <td>    0.666</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_aspects</th>             <td>    1.0667</td> <td>    0.632</td> <td>    1.687</td> <td> 0.092</td> <td>   -0.173</td> <td>    2.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_choose</th>              <td>   -1.9216</td> <td>    1.123</td> <td>   -1.711</td> <td> 0.087</td> <td>   -4.123</td> <td>    0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_friends</th>             <td>   -0.6738</td> <td>    0.699</td> <td>   -0.964</td> <td> 0.335</td> <td>   -2.044</td> <td>    0.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_read</th>                <td>   -1.5931</td> <td>    0.907</td> <td>   -1.756</td> <td> 0.079</td> <td>   -3.371</td> <td>    0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_family</th>                   <td>   -0.3732</td> <td>   62.882</td> <td>   -0.006</td> <td> 0.995</td> <td> -123.621</td> <td>  122.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_education</th>                <td>   -0.9939</td> <td>   62.884</td> <td>   -0.016</td> <td> 0.987</td> <td> -124.244</td> <td>  122.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_media</th>                    <td>    1.0616</td> <td>   62.887</td> <td>    0.017</td> <td> 0.987</td> <td> -122.194</td> <td>  124.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_improvement</th>              <td>    0.2452</td> <td>   62.880</td> <td>    0.004</td> <td> 0.997</td> <td> -122.998</td> <td>  123.488</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_culture</th>                  <td>   -0.4823</td> <td>   62.882</td> <td>   -0.008</td> <td> 0.994</td> <td> -123.729</td> <td>  122.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_citizenship</th>              <td>   -1.6144</td> <td>   62.887</td> <td>   -0.026</td> <td> 0.980</td> <td> -124.871</td> <td>  121.642</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_num_lang</th>                 <td>   -7.7542</td> <td>    4.549</td> <td>   -1.705</td> <td> 0.088</td> <td>  -16.670</td> <td>    1.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_years_learning</th>           <td>   -1.1054</td> <td>    0.555</td> <td>   -1.991</td> <td> 0.046</td> <td>   -2.193</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_home_speaker</th>             <td>    0.4400</td> <td>    2.132</td> <td>    0.206</td> <td> 0.837</td> <td>   -3.739</td> <td>    4.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_home_spoken</th>              <td>    4.3105</td> <td>    4.281</td> <td>    1.007</td> <td> 0.314</td> <td>   -4.080</td> <td>   12.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A/B</th>                           <td>    0.4688</td> <td> 1320.465</td> <td>    0.000</td> <td> 1.000</td> <td>-2587.595</td> <td> 2588.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B/C</th>                           <td>    2.1944</td> <td>    0.525</td> <td>    4.179</td> <td> 0.000</td> <td>    1.165</td> <td>    3.224</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                             OrderedModel Results                             \n",
       "==============================================================================\n",
       "Dep. Variable:     feel_current_grade   Log-Likelihood:                -21.713\n",
       "Model:                   OrderedModel   AIC:                             123.4\n",
       "Method:            Maximum Likelihood   BIC:                             220.7\n",
       "Date:                Mon, 12 Jun 2023                                         \n",
       "Time:                        15:01:40                                         \n",
       "No. Observations:                  84                                         \n",
       "Df Residuals:                      44                                         \n",
       "Df Model:                          40                                         \n",
       "=================================================================================================\n",
       "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "motivator_family_continue         0.3639      0.324      1.122      0.262      -0.272       1.000\n",
       "motivator_family_encourage       -1.3226      0.745     -1.776      0.076      -2.782       0.137\n",
       "motivator_family_stressed        -0.3700      0.320     -1.158      0.247      -0.996       0.256\n",
       "motivator_family_important        0.7969      0.499      1.597      0.110      -0.181       1.775\n",
       "motivator_required                0.9357      0.581      1.609      0.108      -0.204       2.075\n",
       "motivator_choose_not             -1.3144      0.800     -1.643      0.100      -2.882       0.253\n",
       "motivator_nervous                 0.5947      0.419      1.421      0.155      -0.226       1.415\n",
       "motivator_difficult               1.5374      0.911      1.688      0.091      -0.248       3.323\n",
       "motivator_newspapers             -0.8395      0.465     -1.807      0.071      -1.750       0.071\n",
       "motivator_tv                      1.7224      0.965      1.785      0.074      -0.169       3.614\n",
       "motivator_understand              0.1639      0.294      0.558      0.577      -0.412       0.740\n",
       "motivator_speak                   1.8990      1.074      1.768      0.077      -0.206       4.004\n",
       "motivator_many                   -0.4268      0.380     -1.124      0.261      -1.171       0.318\n",
       "motivator_practical              -1.1088      0.643     -1.725      0.084      -2.368       0.151\n",
       "motivator_career                 -0.4025      0.305     -1.321      0.187      -1.000       0.195\n",
       "motivator_job                     1.7990      1.144      1.573      0.116      -0.442       4.041\n",
       "motivator_educated                1.1274      0.899      1.254      0.210      -0.635       2.889\n",
       "motivator_converse                0.5222      0.667      0.783      0.434      -0.786       1.830\n",
       "motivator_understand_cultural     1.4142      0.898      1.575      0.115      -0.346       3.174\n",
       "motivator_interact               -1.7965      1.089     -1.650      0.099      -3.930       0.337\n",
       "motivator_great                   1.8368      1.051      1.748      0.080      -0.223       3.897\n",
       "motivator_communicate             1.1038      0.859      1.286      0.199      -0.579       2.786\n",
       "motivator_natural                -1.7980      1.094     -1.643      0.100      -3.943       0.347\n",
       "motivator_fluent                 -2.0639      1.393     -1.482      0.138      -4.793       0.666\n",
       "motivator_aspects                 1.0667      0.632      1.687      0.092      -0.173       2.306\n",
       "motivator_choose                 -1.9216      1.123     -1.711      0.087      -4.123       0.280\n",
       "motivator_friends                -0.6738      0.699     -0.964      0.335      -2.044       0.697\n",
       "motivator_read                   -1.5931      0.907     -1.756      0.079      -3.371       0.185\n",
       "rank_family                      -0.3732     62.882     -0.006      0.995    -123.621     122.874\n",
       "rank_education                   -0.9939     62.884     -0.016      0.987    -124.244     122.256\n",
       "rank_media                        1.0616     62.887      0.017      0.987    -122.194     124.318\n",
       "rank_improvement                  0.2452     62.880      0.004      0.997    -122.998     123.488\n",
       "rank_culture                     -0.4823     62.882     -0.008      0.994    -123.729     122.764\n",
       "rank_citizenship                 -1.6144     62.887     -0.026      0.980    -124.871     121.642\n",
       "demo_num_lang                    -7.7542      4.549     -1.705      0.088     -16.670       1.161\n",
       "demo_years_learning              -1.1054      0.555     -1.991      0.046      -2.193      -0.017\n",
       "demo_home_speaker                 0.4400      2.132      0.206      0.837      -3.739       4.619\n",
       "demo_home_spoken                  4.3105      4.281      1.007      0.314      -4.080      12.701\n",
       "A/B                               0.4688   1320.465      0.000      1.000   -2587.595    2588.532\n",
       "B/C                               2.1944      0.525      4.179      0.000       1.165       3.224\n",
       "=================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct an ordered model for the current grade\n",
    "current_grade_model = OrderedModel(grade_df['feel_current_grade'], \n",
    "                                   grade_df[full_cols + rank_only + controlling_list],\n",
    "                                   hasconst=False).fit(method='bfgs')\n",
    "current_grade_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.407930\n",
      "         Iterations: 60\n",
      "         Function evaluations: 63\n",
      "         Gradient evaluations: 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OrderedModel Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>feel_expected_grade</td> <th>  Log-Likelihood:    </th> <td> -34.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>OrderedModel</td>     <th>  AIC:               </th> <td>   148.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>           <td>Maximum Likelihood</td>  <th>  BIC:               </th> <td>   245.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 12 Jun 2023</td>   <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>14:59:06</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>    84</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>    44</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    40</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_continue</th>     <td>    0.1427</td> <td>    0.141</td> <td>    1.013</td> <td> 0.311</td> <td>   -0.134</td> <td>    0.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_encourage</th>    <td>   -0.1068</td> <td>    0.203</td> <td>   -0.527</td> <td> 0.598</td> <td>   -0.504</td> <td>    0.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_stressed</th>     <td>    0.0806</td> <td>    0.124</td> <td>    0.649</td> <td> 0.516</td> <td>   -0.163</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_family_important</th>    <td>   -0.0340</td> <td>    0.227</td> <td>   -0.150</td> <td> 0.881</td> <td>   -0.479</td> <td>    0.411</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_required</th>            <td>    0.0620</td> <td>    0.096</td> <td>    0.646</td> <td> 0.518</td> <td>   -0.126</td> <td>    0.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_choose_not</th>          <td>   -0.4899</td> <td>    0.218</td> <td>   -2.246</td> <td> 0.025</td> <td>   -0.917</td> <td>   -0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_nervous</th>             <td>   -0.0665</td> <td>    0.137</td> <td>   -0.484</td> <td> 0.628</td> <td>   -0.336</td> <td>    0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_difficult</th>           <td>    0.5855</td> <td>    0.160</td> <td>    3.658</td> <td> 0.000</td> <td>    0.272</td> <td>    0.899</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_newspapers</th>          <td>   -0.2476</td> <td>    0.145</td> <td>   -1.711</td> <td> 0.087</td> <td>   -0.531</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_tv</th>                  <td>    0.3108</td> <td>    0.182</td> <td>    1.705</td> <td> 0.088</td> <td>   -0.046</td> <td>    0.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_understand</th>          <td>    0.0250</td> <td>    0.151</td> <td>    0.166</td> <td> 0.869</td> <td>   -0.271</td> <td>    0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_speak</th>               <td>    0.3806</td> <td>    0.266</td> <td>    1.433</td> <td> 0.152</td> <td>   -0.140</td> <td>    0.901</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_many</th>                <td>   -0.0865</td> <td>    0.189</td> <td>   -0.458</td> <td> 0.647</td> <td>   -0.457</td> <td>    0.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_practical</th>           <td>   -0.2816</td> <td>    0.151</td> <td>   -1.860</td> <td> 0.063</td> <td>   -0.578</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_career</th>              <td>   -0.0677</td> <td>    0.121</td> <td>   -0.557</td> <td> 0.577</td> <td>   -0.306</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_job</th>                 <td>    0.4055</td> <td>    0.161</td> <td>    2.512</td> <td> 0.012</td> <td>    0.089</td> <td>    0.722</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_educated</th>            <td>    0.2177</td> <td>    0.198</td> <td>    1.100</td> <td> 0.271</td> <td>   -0.170</td> <td>    0.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_converse</th>            <td>   -0.0372</td> <td>    0.300</td> <td>   -0.124</td> <td> 0.901</td> <td>   -0.624</td> <td>    0.550</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_understand_cultural</th> <td>    0.3000</td> <td>    0.263</td> <td>    1.141</td> <td> 0.254</td> <td>   -0.215</td> <td>    0.815</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_interact</th>            <td>   -0.1269</td> <td>    0.198</td> <td>   -0.640</td> <td> 0.522</td> <td>   -0.515</td> <td>    0.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_great</th>               <td>    0.2900</td> <td>    0.275</td> <td>    1.055</td> <td> 0.292</td> <td>   -0.249</td> <td>    0.829</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_communicate</th>         <td>    0.0553</td> <td>    0.189</td> <td>    0.292</td> <td> 0.770</td> <td>   -0.316</td> <td>    0.427</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_natural</th>             <td>   -0.3361</td> <td>    0.275</td> <td>   -1.220</td> <td> 0.222</td> <td>   -0.876</td> <td>    0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_fluent</th>              <td>   -0.6586</td> <td>    0.287</td> <td>   -2.298</td> <td> 0.022</td> <td>   -1.221</td> <td>   -0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_aspects</th>             <td>   -0.0507</td> <td>    0.249</td> <td>   -0.204</td> <td> 0.838</td> <td>   -0.538</td> <td>    0.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_choose</th>              <td>   -0.4863</td> <td>    0.155</td> <td>   -3.131</td> <td> 0.002</td> <td>   -0.791</td> <td>   -0.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_friends</th>             <td>   -0.0281</td> <td>    0.168</td> <td>   -0.167</td> <td> 0.867</td> <td>   -0.357</td> <td>    0.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motivator_read</th>                <td>   -0.1059</td> <td>    0.172</td> <td>   -0.617</td> <td> 0.537</td> <td>   -0.442</td> <td>    0.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_family</th>                   <td>    0.4159</td> <td>   27.624</td> <td>    0.015</td> <td> 0.988</td> <td>  -53.725</td> <td>   54.557</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_education</th>                <td>    0.1978</td> <td>   27.624</td> <td>    0.007</td> <td> 0.994</td> <td>  -53.944</td> <td>   54.340</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_media</th>                    <td>    0.1553</td> <td>   27.624</td> <td>    0.006</td> <td> 0.996</td> <td>  -53.987</td> <td>   54.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_improvement</th>              <td>    0.1651</td> <td>   27.623</td> <td>    0.006</td> <td> 0.995</td> <td>  -53.976</td> <td>   54.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_culture</th>                  <td>    0.3474</td> <td>   27.624</td> <td>    0.013</td> <td> 0.990</td> <td>  -53.794</td> <td>   54.489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_citizenship</th>              <td>   -0.1980</td> <td>   27.624</td> <td>   -0.007</td> <td> 0.994</td> <td>  -54.340</td> <td>   53.944</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_num_lang</th>                 <td>   -1.5236</td> <td>    0.544</td> <td>   -2.801</td> <td> 0.005</td> <td>   -2.590</td> <td>   -0.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_years_learning</th>           <td>   -0.4184</td> <td>    0.152</td> <td>   -2.758</td> <td> 0.006</td> <td>   -0.716</td> <td>   -0.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_home_speaker</th>             <td>    0.6531</td> <td>    0.947</td> <td>    0.690</td> <td> 0.490</td> <td>   -1.203</td> <td>    2.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demo_home_spoken</th>              <td>   -0.9384</td> <td>    1.108</td> <td>   -0.847</td> <td> 0.397</td> <td>   -3.109</td> <td>    1.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A/B</th>                           <td>    0.3145</td> <td>  580.077</td> <td>    0.001</td> <td> 1.000</td> <td>-1136.616</td> <td> 1137.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B/C</th>                           <td>    0.9529</td> <td>    0.219</td> <td>    4.352</td> <td> 0.000</td> <td>    0.524</td> <td>    1.382</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                              OrderedModel Results                             \n",
       "===============================================================================\n",
       "Dep. Variable:     feel_expected_grade   Log-Likelihood:                -34.266\n",
       "Model:                    OrderedModel   AIC:                             148.5\n",
       "Method:             Maximum Likelihood   BIC:                             245.8\n",
       "Date:                 Mon, 12 Jun 2023                                         \n",
       "Time:                         14:59:06                                         \n",
       "No. Observations:                   84                                         \n",
       "Df Residuals:                       44                                         \n",
       "Df Model:                           40                                         \n",
       "=================================================================================================\n",
       "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "motivator_family_continue         0.1427      0.141      1.013      0.311      -0.134       0.419\n",
       "motivator_family_encourage       -0.1068      0.203     -0.527      0.598      -0.504       0.290\n",
       "motivator_family_stressed         0.0806      0.124      0.649      0.516      -0.163       0.324\n",
       "motivator_family_important       -0.0340      0.227     -0.150      0.881      -0.479       0.411\n",
       "motivator_required                0.0620      0.096      0.646      0.518      -0.126       0.250\n",
       "motivator_choose_not             -0.4899      0.218     -2.246      0.025      -0.917      -0.062\n",
       "motivator_nervous                -0.0665      0.137     -0.484      0.628      -0.336       0.203\n",
       "motivator_difficult               0.5855      0.160      3.658      0.000       0.272       0.899\n",
       "motivator_newspapers             -0.2476      0.145     -1.711      0.087      -0.531       0.036\n",
       "motivator_tv                      0.3108      0.182      1.705      0.088      -0.046       0.668\n",
       "motivator_understand              0.0250      0.151      0.166      0.869      -0.271       0.321\n",
       "motivator_speak                   0.3806      0.266      1.433      0.152      -0.140       0.901\n",
       "motivator_many                   -0.0865      0.189     -0.458      0.647      -0.457       0.284\n",
       "motivator_practical              -0.2816      0.151     -1.860      0.063      -0.578       0.015\n",
       "motivator_career                 -0.0677      0.121     -0.557      0.577      -0.306       0.170\n",
       "motivator_job                     0.4055      0.161      2.512      0.012       0.089       0.722\n",
       "motivator_educated                0.2177      0.198      1.100      0.271      -0.170       0.606\n",
       "motivator_converse               -0.0372      0.300     -0.124      0.901      -0.624       0.550\n",
       "motivator_understand_cultural     0.3000      0.263      1.141      0.254      -0.215       0.815\n",
       "motivator_interact               -0.1269      0.198     -0.640      0.522      -0.515       0.262\n",
       "motivator_great                   0.2900      0.275      1.055      0.292      -0.249       0.829\n",
       "motivator_communicate             0.0553      0.189      0.292      0.770      -0.316       0.427\n",
       "motivator_natural                -0.3361      0.275     -1.220      0.222      -0.876       0.204\n",
       "motivator_fluent                 -0.6586      0.287     -2.298      0.022      -1.221      -0.097\n",
       "motivator_aspects                -0.0507      0.249     -0.204      0.838      -0.538       0.437\n",
       "motivator_choose                 -0.4863      0.155     -3.131      0.002      -0.791      -0.182\n",
       "motivator_friends                -0.0281      0.168     -0.167      0.867      -0.357       0.301\n",
       "motivator_read                   -0.1059      0.172     -0.617      0.537      -0.442       0.231\n",
       "rank_family                       0.4159     27.624      0.015      0.988     -53.725      54.557\n",
       "rank_education                    0.1978     27.624      0.007      0.994     -53.944      54.340\n",
       "rank_media                        0.1553     27.624      0.006      0.996     -53.987      54.298\n",
       "rank_improvement                  0.1651     27.623      0.006      0.995     -53.976      54.306\n",
       "rank_culture                      0.3474     27.624      0.013      0.990     -53.794      54.489\n",
       "rank_citizenship                 -0.1980     27.624     -0.007      0.994     -54.340      53.944\n",
       "demo_num_lang                    -1.5236      0.544     -2.801      0.005      -2.590      -0.457\n",
       "demo_years_learning              -0.4184      0.152     -2.758      0.006      -0.716      -0.121\n",
       "demo_home_speaker                 0.6531      0.947      0.690      0.490      -1.203       2.509\n",
       "demo_home_spoken                 -0.9384      1.108     -0.847      0.397      -3.109       1.233\n",
       "A/B                               0.3145    580.077      0.001      1.000   -1136.616    1137.245\n",
       "B/C                               0.9529      0.219      4.352      0.000       0.524       1.382\n",
       "=================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct an ordered model for the current grade\n",
    "expected_grade_model = OrderedModel(grade_df['feel_expected_grade'], \n",
    "                                   grade_df[full_cols + rank_only + controlling_list],\n",
    "                                   hasconst=False).fit(method='bfgs')\n",
    "expected_grade_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
